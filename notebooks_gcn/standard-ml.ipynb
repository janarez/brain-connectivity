{
 "cells": [
  {
   "source": [
    "# Standard Machine Learning methods\n",
    "\n",
    "Here, we examine the performance of standard machine learning methods from the `scikit-learn` toolkit on our dataset of functional connectivities only.\n",
    "\n",
    "The goal is to examine performance on these shallow methods to get a set of baseline results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data'\n",
    "PICKLE_FOLDER = '../pickles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/fc-pearson.pickle', 'rb') as f:\n",
    "    fc_pearson = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/fc-spearman.pickle', 'rb') as f:\n",
    "    fc_spearman = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/fc-partial-pearson.pickle', 'rb') as f:\n",
    "    fc_partial_pearson = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples, total_brain_regions, _ = fc_pearson.shape\n",
    "\n",
    "print(f'Subjects: {total_samples}')\n",
    "print(f'Brain regions: {total_brain_regions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(f'{DATA_FOLDER}/patients-cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.head(3)"
   ]
  },
  {
   "source": [
    "## Split data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/test-indices.pickle', 'rb') as f:\n",
    "    test_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset.\n",
    "fc = fc_pearson.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = fc[test_indices]\n",
    "y_test = df_metadata.iloc[test_indices][\"target\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = ~np.isin(np.arange(total_samples), test_indices)\n",
    "X_train = fc[train_indices]\n",
    "y_train = df_metadata.iloc[train_indices][\"target\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten FC matrices for ML models.\n",
    "X_test_full = np.reshape(X_test, (-1, total_brain_regions * total_brain_regions))\n",
    "X_train_full = np.reshape(X_train, (-1, total_brain_regions * total_brain_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten FC matrices for ML models, but disregard diagonal and lower triangle.\n",
    "X_test_triag = [np.hstack([row[i+1:] for i, row in enumerate(sample)]) for sample in X_test]\n",
    "X_train_triag = [np.hstack([row[i+1:] for i, row in enumerate(sample)]) for sample in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten FC matrices for ML models, but disregard diagonal and lower triangle. Take absolute value.\n",
    "X_test_triag_abs = np.abs(X_test_triag)\n",
    "X_train_triag_abs = np.abs(X_train_triag)"
   ]
  },
  {
   "source": [
    "## Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_custom(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    print(f\"Accuracy: {(tp+tn)/(fn+tp+tn+fp):.2f}\")\n",
    "    print(f\"Recall: {tp}/{fn+tp} ({tp/(fn+tp):.2f})\")\n",
    "    print(f\"Precision: {tp}/{tp+fp} ({tp/(tp+fp):.2f})\")\n",
    "    print()"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation using 7 folds: 140 = 120 + 20.\n",
    "# Per `GridSearchCV` documentation `StratifiedKFold` is used to get balanced folds.\n",
    "NUM_FOLDS = 7\n",
    "grid_kwargs = {\"cv\": NUM_FOLDS, \"n_jobs\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(estimator, estimator_params, grid_kwargs=grid_kwargs, X_data=X_train_triag_abs):\n",
    "    \"\"\"\n",
    "    Performs cross-validation using train dataset on estimator.\n",
    "    Optionally takes grid search settings.\n",
    "    \"\"\"\n",
    "    grid = GridSearchCV(estimator, estimator_params, **grid_kwargs)\n",
    "    grid.fit(X_data, y_train)\n",
    "    results = pd.DataFrame(grid.cv_results_)\n",
    "    y_pred = grid.best_estimator_.predict(X_data)\n",
    "    confusion_matrix_custom(y_train.values, y_pred)\n",
    "\n",
    "    cv_params = [\"params\", \"mean_test_score\", \"std_test_score\"] + [f\"split{i}_test_score\" for i in range(NUM_FOLDS)]\n",
    "\n",
    "    return results.sort_values(by=['rank_test_score'])[cv_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we see the full `params` field.\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "source": [
    "## ML Models\n",
    "- KNN\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVC\n",
    "- Elastic Net based logistic regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest neighbor.\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\"n_neighbors\": [1, 2, 3, 4, 5, 7, 10], \"p\": [1, 2], \"weights\": (\"uniform\", \"distance\")}\n",
    "cross_validate(knn, knn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes.\n",
    "gnb = GaussianNB()\n",
    "gnb_params = {\"var_smoothing\": [1e-15, 1e-10, 1e-9, 1e-8, 1e-5, 1e-2, 1e-1]}\n",
    "cross_validate(gnb, gnb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest.\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {\"n_estimators\": [50, 100, 200, 500], \"max_depth\": [1,2,3,5, None], \"criterion\": (\"entropy\", \"gini\")}\n",
    "cross_validate(rf, rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC.\n",
    "svc = SVC()\n",
    "svc_params = {\"C\": [0.1, 1, 10, 100, 1000], \"kernel\": (\"poly\", \"rbf\", \"sigmoid\"), \"degree\": [1,2,3,4]}\n",
    "cross_validate(svc, svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net.\n",
    "eln = SGDClassifier()\n",
    "eln_params = {\"loss\": [\"log\", \"modified_huber\"], \"alpha\": [0.1, 0.01, 0.001], \"penalty\": [\"elasticnet\"], \"l1_ratio\": [0.15, 0.25, 0.5, 0.7], \"max_iter\": [1000, 10000, 20000]}\n",
    "cross_validate(eln, eln_params)"
   ]
  },
  {
   "source": [
    "## Observations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- 1. KNN\n",
    "\n",
    "Mean test score is best at 3 neighbors (71 += 6 %). Single and 5 neighbors produce similar and slightly worse scores (70 += 8 %). Interestingly the score falls sharply for 2 neighbors to (61 += 10 %) and 4 neighbors (61 += 7 %). There are always weak and strong folds: 55 - 85 %, hence large std.\n",
    "\n",
    "Hyperparamters `p` and `weigths` don't affect results in a significant way.\n",
    "\n",
    "\n",
    "- 2. Naive Bayes\n",
    "\n",
    "Independantly of the `var_smoothing` hyperparameter the perfomance is consistently (79 += 9 %). Again, a large variance is obsererved. Weak folds get 65 to 70 percent and strong ones up to 90 % accuracy.\n",
    "\n",
    "- 3. Random Forest\n",
    "\n",
    "Random forests achieve 80 % accuracy, but the variance is large 10 - 13 %. Some folds are classified hundred percent correctly. The effect of hyperparameters results in about 4 % diffence, which is only third of variance.\n",
    "\n",
    "- 4. SVC\n",
    "\n",
    "Low polynomial kernels perform the best. They are not particularly sensitive to choice of `C` and `degree=[1,2,3]`. The accuracy is (85 += 10 %). A clear pattern of easy and hard folds can be observed. Four folds get 95 % accuracy and three 70 - 75 % accuracy.\n",
    "\n",
    "- 5. Elastic Net alÃ¡ logistic regression\n",
    "\n",
    "This classifier proved to be the best with accuracy (87 += 8 %). It adds two percent to mean and sheds two percent from std in comparison to SVC. The `hinge` loss for Elastic net is actually equivalent to linear SVC, while the `log` loss gives logistic regression. Generally, the folds are not strictly weak or strong. Ussually, we get a weak one, one or two middle ones and then strong ones."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The above results are for full 8100 FC matrices.\n",
    "\n",
    " - Removing lower triangle and diagonal does not change results at all.\n",
    " - Taking absolute value reduces accuracy on average by 3 % and std by 1-2 %.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Explainability"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random forest and gini impurance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='gini', max_depth=3, n_estimators=50) # Best RF from above.\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.reshape(rf.feature_importances_, (total_brain_regions, total_brain_regions)), cmap=\"YlGnBu\")\n",
    "plt.title(f\"Important features for random forest model based on Gini.\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "#### Save the importance matrix for dataset creation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_matrix = np.reshape(np.where(rf.feature_importances_ > 0, True, False), (total_brain_regions, total_brain_regions))\n",
    "\n",
    "with open(f'{PICKLE_FOLDER}/gini-importance-matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(gini_matrix, f)"
   ]
  },
  {
   "source": [
    "### Best model - SGD classifier - and its coefficients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best SGD from above with std < 10 %.\n",
    "eln = SGDClassifier(alpha=0.01, l1_ratio=0.5, loss='log', max_iter=20000, penalty='elasticnet')\n",
    "eln.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.abs(np.reshape(eln.coef_, (total_brain_regions, total_brain_regions))), cmap=\"YlGnBu\")\n",
    "plt.title(f\"Feature coefficients of SGD classifier.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "y = [np.sum(np.abs(eln.coef_) > i) for i in x]\n",
    "plt.plot(x, y)\n",
    "plt.title(f\"Number of coefficients larger than 'x'.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the coefficient matrix for dataset creation.\n",
    "sgd_matrix = np.reshape(np.where(eln.coef_ > 0, True, False), (total_brain_regions, total_brain_regions))\n",
    "\n",
    "with open(f'{PICKLE_FOLDER}/sgd-coefficients-matrix.pickle', 'wb') as f:\n",
    "    pickle.dump(sgd_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "b645526185d99215aa93b35893ebde63767219db82c922476bfeda3d99cf53d5"
   }
  },
  "interpreter": {
   "hash": "9c40931cbb4a31228df7bc840fc8745c5509fc7c9b0d60dae36a005e5fe0dba9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}