{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd09c40931cbb4a31228df7bc840fc8745c5509fc7c9b0d60dae36a005e5fe0dba9",
   "display_name": "Python 3.7.6 64-bit ('.venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Graph Neural Networks Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data'\n",
    "PICKLE_FOLDER = '../pickles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/timeseries.pickle', 'rb') as f:\n",
    "    ts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples, total_brain_regions, ts_length = ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(f'{DATA_FOLDER}/patients-cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      age  sex  target\n",
       "0  24.750    1       0\n",
       "1  27.667    1       0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24.750</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27.667</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_metadata.head(2)"
   ]
  },
  {
   "source": [
    "### Select connectivity dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.1                         # 0.01, 0.05, 0.1, 0.15\n",
    "EDGE_FEATURES = 'binary'                # 'binary', 'real'\n",
    "CORR_TYPE = 'pearson'                   # 'pearson', 'spearman', 'partial-pearson'\n",
    "THRESHOLD_METHOD = 'abs-sample-diff'    # 'abs-sample-diff', 'abs-group-avg-diff'\n",
    "THRESHOLD_TYPE = 'min'                  # 'min', 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_file = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}-{THRESHOLD_METHOD}/{THRESHOLD_TYPE}-th-{THRESHOLD}-{EDGE_FEATURES}.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fc_file, 'rb') as f:\n",
    "    edge_index_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(190, 90, 90)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "edge_index_matrix.shape"
   ]
  },
  {
   "source": [
    "## Split data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/test-indices.pickle', 'rb') as f:\n",
    "    test_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(set(range(total_samples)) - set(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = df_metadata.iloc[train_indices][\"target\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set size: 140\nTest set size: 50\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set size: {len(train_indices)}')\n",
    "print(f'Test set size: {len(test_indices)}')"
   ]
  },
  {
   "source": [
    "## Extend dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SURROGATES = 5                    # 5\n",
    "SURROGATE_METHOD = 'iaaft'          # 'iaaft', 'aaft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}/timeseries-{SURROGATE_METHOD}-{N_SURROGATES}.pickle', 'rb') as f:\n",
    "    ts_surrogates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extra data: (950, 90, 400)\n5.0 surrogates per sample\n"
     ]
    }
   ],
   "source": [
    "print(f'Extra data: {ts_surrogates.shape}')\n",
    "print(f'{ts_surrogates.shape[0] / total_samples} surrogates per sample')"
   ]
  },
  {
   "source": [
    "Extend only training data. Test set will consist of true data only."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train_surrogates = np.concatenate([ts_surrogates[N_SURROGATES*i:N_SURROGATES*i+N_SURROGATES] for i in train_indices], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(700, 90, 400)"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "ts_train_surrogates.shape"
   ]
  },
  {
   "source": [
    "## Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "source": [
    "### `Data` object fields\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "\n",
    "- `data.edge_index`: Graph connectivity in COO format with shape `[2, num_edges]` and type `torch.long`\n",
    "\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [Data(\n",
    "    x=torch.from_numpy(ts[i]).to(torch.float32),  \n",
    "    edge_index=torch.from_numpy(np.asarray(np.nonzero(edge_index_matrix[i]))).to(torch.int64),\n",
    "    y=torch.tensor([target], dtype=torch.int64)\n",
    ").to(device) for target, i in zip(train_targets, train_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True train data: 840\n"
     ]
    }
   ],
   "source": [
    "print(f'True train data: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension.\n",
    "dataset_ext = [Data(\n",
    "    x=torch.from_numpy(ts_surr).to(torch.float32),  \n",
    "    edge_index=torch.from_numpy(np.asarray(np.nonzero(edge_index_matrix[i]))).to(torch.int64),\n",
    "    y=torch.tensor([target], dtype=torch.int64)\n",
    ").to(device) for target, i, ts_surr in zip(\n",
    "    np.repeat(train_targets, N_SURROGATES),\n",
    "    np.repeat(train_indices, N_SURROGATES),\n",
    "    ts_train_surrogates\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Surrogate train data: 700\n"
     ]
    }
   ],
   "source": [
    "print(f'Surrogate train data: {len(dataset_ext)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.extend(dataset_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extended train data: 840\n"
     ]
    }
   ],
   "source": [
    "print(f'Extended train data: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data object\nEdge index: torch.Size([2, 6044])\nNode features: torch.Size([90, 400])\nTarget: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print('Data object')\n",
    "print(f'Edge index: {dataset[0].edge_index.shape}')\n",
    "print(f'Node features: {dataset[0].x.shape}')\n",
    "print(f'Target: {dataset[0].y.shape}')"
   ]
  },
  {
   "source": [
    "## Define model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineGCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_channels):\n",
    "        super(BaselineGCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(ts_length, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.fc1 = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc1(x)     # CELoss already incorporates `log_softmax`.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BaselineGCN(\n",
       "  (conv1): GCNConv(400, 8)\n",
       "  (conv2): GCNConv(8, 8)\n",
       "  (conv3): GCNConv(8, 8)\n",
       "  (fc1): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "net = BaselineGCN(hidden_channels=8)\n",
    "net.to(device)"
   ]
  },
  {
   "source": [
    "## Train model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-3.5022e-02,  3.5410e-02, -4.1006e-02,  2.3849e-02, -4.2094e-02,\n          7.1125e-02, -2.5770e-03, -6.5332e-02, -5.5606e-02,  4.6088e-03,\n          2.1107e-02,  4.5986e-02,  1.9869e-02, -3.6340e-02, -1.1291e-04,\n         -3.8757e-02,  1.2293e-04,  7.2001e-03,  2.1045e-02,  4.8760e-02,\n          9.3344e-03,  1.6418e-02,  3.1810e-02,  3.6885e-02,  2.2806e-02,\n         -3.0740e-02,  5.9031e-02, -5.8547e-02,  2.1661e-02, -2.1815e-02,\n          5.2773e-02, -5.6954e-02, -5.9659e-03,  5.2666e-02,  4.8222e-02,\n         -1.1074e-02, -6.7001e-03,  4.6509e-03, -2.1060e-02,  5.4291e-03,\n          1.6698e-02,  7.2888e-02, -7.6186e-02,  9.5884e-03,  6.4558e-02,\n          7.9487e-02, -4.9284e-03, -2.5523e-02, -2.3667e-02,  9.1258e-04,\n         -8.1411e-02, -1.2315e-02, -6.9843e-02, -1.2384e-02,  7.7733e-03,\n          9.3262e-03, -1.4273e-02, -1.1894e-02,  2.9109e-02,  4.4057e-02,\n          2.4401e-02,  9.1332e-03,  1.2144e-02,  1.9471e-02],\n        [ 1.3108e-02, -1.2711e-02,  2.5043e-02,  5.9712e-02, -1.6951e-02,\n         -1.1046e-02, -5.6054e-02, -5.0804e-02, -6.3270e-03, -4.5003e-02,\n          2.2315e-02,  8.0867e-02,  9.0319e-02,  2.1306e-02, -1.3323e-02,\n          2.2428e-02, -2.6670e-02,  4.0872e-02,  1.7363e-02,  1.5974e-02,\n          3.3401e-02, -7.2538e-03, -5.5763e-03,  5.0816e-03,  6.3345e-02,\n         -3.0916e-02,  6.8141e-02, -6.0066e-02,  4.9271e-02, -6.3473e-02,\n         -5.7918e-02, -4.1862e-02,  1.3118e-02,  5.0280e-02,  4.5092e-02,\n         -1.6023e-02,  4.1154e-03,  3.2444e-02, -9.0055e-02,  1.1077e-02,\n          2.2496e-02,  4.0174e-02, -3.4127e-02,  3.2918e-02,  3.0360e-02,\n          7.1164e-03, -2.3535e-02, -5.6110e-02,  2.3938e-02, -9.0552e-02,\n         -4.8601e-02, -6.8027e-03, -1.2284e-02, -1.1198e-03,  4.6315e-03,\n          5.9715e-03, -7.7906e-02, -1.6260e-02, -6.1934e-03, -2.7514e-02,\n          1.9154e-02,  4.3924e-03, -3.0048e-02,  7.8844e-02],\n        [ 4.1715e-03, -7.8589e-03, -4.3098e-02,  6.1082e-02, -5.2078e-02,\n          3.4016e-02, -6.0134e-02, -1.9781e-02, -7.3919e-02, -2.9102e-02,\n          9.4427e-02,  1.4507e-01,  3.8107e-03, -5.9435e-03,  1.5577e-02,\n         -6.8108e-02, -2.2470e-02, -2.3318e-02,  2.1856e-02,  3.6635e-02,\n          5.2858e-02, -1.3717e-02, -6.1519e-03,  6.3334e-02,  4.0225e-03,\n         -4.0040e-02,  1.0430e-01, -8.4814e-02,  2.7357e-02, -8.6169e-02,\n          6.2115e-02, -8.9117e-03,  2.6555e-02,  8.1944e-02,  3.0846e-02,\n         -8.4974e-02,  2.1899e-02,  7.2118e-02, -9.8562e-02,  7.7030e-03,\n         -9.8315e-03,  3.8963e-02, -3.4870e-03,  3.6202e-02,  8.2991e-02,\n          2.2774e-02, -3.3355e-04, -9.7291e-02,  2.1245e-02, -9.0684e-02,\n         -3.4964e-02, -3.6583e-02, -4.0232e-02,  1.8499e-02,  4.7838e-02,\n         -9.0751e-03,  1.6019e-02, -8.2738e-02, -1.7098e-02,  8.3096e-02,\n         -3.6883e-02,  6.1972e-02, -5.9018e-02,  1.3324e-02],\n        [ 4.5582e-02,  2.1796e-02, -6.7363e-02,  4.4460e-02, -3.6141e-02,\n          9.5526e-02,  1.9119e-03, -6.1332e-02, -6.2090e-02,  1.0109e-02,\n          4.9282e-02,  6.2978e-02,  9.0254e-02, -6.0439e-02, -1.1730e-02,\n         -3.8359e-02, -6.5282e-02,  2.7149e-02,  8.5069e-02,  5.1019e-02,\n         -3.4861e-02, -3.9782e-02, -1.2300e-02,  7.1272e-02,  3.4455e-02,\n         -1.0328e-02,  1.0705e-01, -6.7774e-02, -2.7277e-02, -4.5947e-03,\n          7.0909e-02,  1.2086e-02,  2.5343e-03,  2.8731e-02,  1.1157e-01,\n         -5.7388e-02,  1.9624e-02,  6.1749e-02, -6.9406e-02,  1.5194e-04,\n         -4.7803e-02,  9.6256e-02, -1.3858e-01, -4.7656e-03,  7.3865e-02,\n          4.0335e-02,  1.7099e-02, -5.8644e-02, -5.2032e-03, -2.4817e-02,\n         -9.9176e-02,  4.0755e-03, -1.2325e-02,  5.8731e-03,  1.1192e-01,\n          4.4594e-02,  1.4902e-02,  2.8404e-02, -1.3956e-02,  1.7441e-02,\n          6.5268e-02, -3.1296e-02, -9.4414e-03,  3.9643e-02]], device='cuda:0',\n       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dropout'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-59179fa7de49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0moptimizr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Compute the loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\brain-connectivity\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-2da702541705>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# 3. Apply a final classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# CELoss already incorporates `log_softmax`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'dropout'"
     ]
    }
   ],
   "source": [
    "for kfold, (train_index, val_index) in enumerate(skf.split(np.zeros(len(train_targets)), train_targets)):\n",
    "    \n",
    "    # Init model.\n",
    "    net = BaselineGCN(hidden_channels=64).to(device)\n",
    "    optimizr = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    net.train()\n",
    "\n",
    "    # Prepare data.\n",
    "    X_train = [dataset[i] for i in train_index]\n",
    "    X_val = [dataset[i] for i in val_index]\n",
    "    \n",
    "    trainloader = DataLoader(X_train, batch_size=4, shuffle=True)\n",
    "    valloader = DataLoader(X_val, batch_size=4, shuffle=False)\n",
    "\n",
    "    # Train.\n",
    "    epoch_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = 0.\n",
    "        epoch_size = 0\n",
    "        \n",
    "        for data in trainloader:\n",
    "            optimizr.zero_grad()\n",
    "\n",
    "            outputs = net(data)\n",
    "            \n",
    "            loss = criterion(outputs, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizr.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_size += 1\n",
    "\n",
    "        epoch_losses.append(running_loss / epoch_size)\n",
    "\n",
    "    # Plot training loss.\n",
    "    plt.plot(range(EPOCHS), epoch_losses)\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate fold.\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "\n",
    "        for data in valloader:\n",
    "            outputs = net(data)\n",
    "\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "\n",
    "            total += data.y.size(0)\n",
    "\n",
    "            labels = data.y.view(-1)\n",
    "\n",
    "            pred_positives = predicted == 1\n",
    "            label_positives = labels == 1\n",
    "\n",
    "            tp += (pred_positives & label_positives).sum().item()\n",
    "            tn += (~pred_positives & ~label_positives).sum().item()\n",
    "            fp += (pred_positives & ~label_positives).sum().item()\n",
    "            fn += (~pred_positives & label_positives).sum().item()\n",
    "\n",
    "    print('===========================================')\n",
    "    print(f'Accuracy: {(tp + tn) / total * 100:.2f} %')\n",
    "    print(f'Precision: {tp / (tp + fp) * 100:.2f} %')\n",
    "    print(f'Recall: {tp / (tp + fn) * 100:.2f} %')\n",
    "    print(f'TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}')\n",
    "    print('===========================================')\n",
    "\n",
    "    print(f'Finished fold #{kfold}\\n')\n",
    "\n",
    "print('Finished training')"
   ]
  }
 ]
}