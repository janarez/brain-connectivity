{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "7ff990880d280141c4c874f19733d121bb8e003ad831d22b66270b3621cedc78"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exploring GCN #2\n",
    "\n",
    "Fully connected graph, correlation as edge features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import spektral as sp"
   ]
  },
  {
   "source": [
    "# Restore preprocessed datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r np_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.read_csv('patients-cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np_timeseries\n",
    "y = df_patients['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(190, 90, 400)\n(190,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('granger-lambda=1-400-nopreprocessing.pickle', 'rb') as f:\n",
    "#     gs = pickle.load(f)\n",
    "\n",
    "# with open('covariance-400-nopreprocessing.pickle', 'rb') as f:\n",
    "#     cov = pickle.load(f)\n",
    "\n",
    "with open('correlation-400-nopreprocessing.pickle', 'rb') as f:\n",
    "    corr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "samples = X.shape[0]            # Number of subjects.       | 190\n",
    "N = regions = X.shape[1]        # Number of regions.        | 90\n",
    "F = X.shape[2]                  # Features - timeseries.    | 400\n",
    "S = 1                           # Edge - correlation        | 1\n",
    "n_classes = 2                   # Control / patient.        | 2"
   ]
  },
  {
   "source": [
    "## Training and testing datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "E_train, E_test, \\\n",
    "A_train, A_test, \\\n",
    "x_train, x_test, \\\n",
    "y_train, y_test = train_test_split(corr, np.ones((samples, N, N)), np.ones((samples)), y, test_size=0.2, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From `example-spectral`.\n",
    "l2_reg = 0.0001            # Regularization rate for l2\n",
    "learning_rate = 0.001     # Learning rate for Adam\n",
    "epochs = 200              # Number of training epochs\n",
    "batch_size = 4              # Batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([None, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "E_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "X_in = tf.keras.layers.Input(shape=(1,))\n",
    "A_in = tf.keras.layers.Input(shape=(None,), sparse=True)\n",
    "E_in = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "X_1 = sp.layers.EdgeConv(32, activation=\"relu\")([X_in, A_in, E_in])\n",
    "X_2 = sp.layers.EdgeConv(32, activation=\"relu\")([X_1, A_in, E_in])\n",
    "X_3 = sp.layers.GlobalSumPool()([X_2])\n",
    "\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(X_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_9\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_22 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_23 (InputLayer)           [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_24 (InputLayer)           [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nedge_conv_11 (EdgeConv)         (None, 32)           64          input_22[0][0]                   \n                                                                 input_23[0][0]                   \n                                                                 input_24[0][0]                   \n__________________________________________________________________________________________________\nedge_conv_12 (EdgeConv)         (None, 32)           2048        edge_conv_11[0][0]               \n                                                                 input_23[0][0]                   \n                                                                 input_24[0][0]                   \n__________________________________________________________________________________________________\nglobal_sum_pool_4 (GlobalSumPoo (1, 32)              0           edge_conv_12[0][0]               \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (1, 1)               33          global_sum_pool_4[0][0]          \n==================================================================================================\nTotal params: 2,145\nTrainable params: 2,145\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = tf.keras.models.Model(inputs=[X_in, A_in, E_in], outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopping_cb = tf.keras.callbacks.EarlyStopping(patience=es_patience, restore_best_weights=True)\n",
    "lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "136.8"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input SparseTensor(indices=Tensor(\"input_23/indices:0\", shape=(None, 2), dtype=int64), values=Tensor(\"input_23/values:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"input_23/shape:0\", shape=(2,), dtype=int64)), but it was called on an input with incompatible shape (None, 90, 90).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input Tensor(\"input_24:0\", shape=(None, 1), dtype=float32), but it was called on an input with incompatible shape (None, 90, 90).\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "in user code:\n\n    c:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\spektral\\layers\\convolutional\\message_passing.py:83 call  *\n        X, A, E = self.get_inputs(inputs)\n    c:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\spektral\\layers\\convolutional\\message_passing.py:146 get_inputs  *\n        assert K.ndim(E) == 2, 'E must have rank 2'\n\n    AssertionError: E must have rank 2\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9df16ced426b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: in user code:\n\n    c:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\spektral\\layers\\convolutional\\message_passing.py:83 call  *\n        X, A, E = self.get_inputs(inputs)\n    c:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\data\\.venv\\lib\\site-packages\\spektral\\layers\\convolutional\\message_passing.py:146 get_inputs  *\n        assert K.ndim(E) == 2, 'E must have rank 2'\n\n    AssertionError: E must have rank 2\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(\n",
    "    [x_train, A_train, E_train],\n",
    "    y_train,\n",
    "    # batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[lr_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Only graph no node features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 4  # Batch size\n",
    "epochs = 200  # Number of training epochs\n",
    "patience = 10  # Patience for early stopping\n",
    "l2_reg = 0.001  # Regularization rate for l2\n",
    "l2 = tf.keras.regularizers.L2(l2=l2_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "X_in = tf.keras.layers.Input(shape=(N, F))\n",
    "A_in = tf.keras.layers.Input((N, N))\n",
    "\n",
    "x = sp.layers.GraphConv(8, activation=\"elu\", kernel_regularizer=l2)([X_in, A_in])\n",
    "x = sp.layers.GraphConv(8, activation=\"elu\", kernel_regularizer=l2)([x, A_in])\n",
    "x = sp.layers.GraphConv(8, activation=\"elu\", kernel_regularizer=l2)([x, A_in])\n",
    "\n",
    "x = sp.layers.GlobalSumPool()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_10\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_15 (InputLayer)           [(None, 90, 400)]    0                                            \n__________________________________________________________________________________________________\ninput_16 (InputLayer)           [(None, 90, 90)]     0                                            \n__________________________________________________________________________________________________\ngraph_conv_8 (GraphConv)        (None, 90, 8)        3208        input_15[0][0]                   \n                                                                 input_16[0][0]                   \n__________________________________________________________________________________________________\ngraph_conv_9 (GraphConv)        (None, 90, 8)        72          graph_conv_8[0][0]               \n                                                                 input_16[0][0]                   \n__________________________________________________________________________________________________\ngraph_conv_10 (GraphConv)       (None, 90, 8)        72          graph_conv_9[0][0]               \n                                                                 input_16[0][0]                   \n__________________________________________________________________________________________________\nglobal_sum_pool_3 (GlobalSumPoo (None, 8)            0           graph_conv_10[0][0]              \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 1)            9           global_sum_pool_3[0][0]          \n==================================================================================================\nTotal params: 3,361\nTrainable params: 3,361\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Model(inputs=[X_in, A_in], outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 19970.5059 - acc: 0.5163 - val_loss: 4865.2441 - val_acc: 0.4444\n",
      "Epoch 2/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 4493.6113 - acc: 0.6078 - val_loss: 5716.4966 - val_acc: 0.2778\n",
      "Epoch 3/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1183.4435 - acc: 0.7451 - val_loss: 7570.2681 - val_acc: 0.5556\n",
      "Epoch 4/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1352.3500 - acc: 0.8039 - val_loss: 3181.0239 - val_acc: 0.4444\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 343.5517 - acc: 0.8235 - val_loss: 4501.6235 - val_acc: 0.5000\n",
      "Epoch 6/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 345.6089 - acc: 0.8301 - val_loss: 4866.2202 - val_acc: 0.4444\n",
      "Epoch 7/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 510.2189 - acc: 0.7974 - val_loss: 5089.5698 - val_acc: 0.4444\n",
      "Epoch 8/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 132.4824 - acc: 0.8627 - val_loss: 3856.4526 - val_acc: 0.4444\n",
      "Epoch 9/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1314.9728 - acc: 0.7451 - val_loss: 3347.6299 - val_acc: 0.3889\n",
      "Epoch 10/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 297.7755 - acc: 0.7386 - val_loss: 3912.8364 - val_acc: 0.6111\n",
      "Epoch 11/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 135.5601 - acc: 0.7974 - val_loss: 4093.1519 - val_acc: 0.6111\n",
      "Epoch 12/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 71.2472 - acc: 0.8235 - val_loss: 3862.1016 - val_acc: 0.6111\n",
      "Epoch 13/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 18.4224 - acc: 0.8235 - val_loss: 3790.6111 - val_acc: 0.6111\n",
      "Epoch 14/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 291.3860 - acc: 0.8105 - val_loss: 4270.6416 - val_acc: 0.5556\n",
      "Epoch 15/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 190.5169 - acc: 0.7516 - val_loss: 3605.3069 - val_acc: 0.6111\n",
      "Epoch 16/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 37.1042 - acc: 0.7843 - val_loss: 3600.7261 - val_acc: 0.5556\n",
      "Epoch 17/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 17.3954 - acc: 0.8301 - val_loss: 3440.7700 - val_acc: 0.5556\n",
      "Epoch 18/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 15.7556 - acc: 0.8235 - val_loss: 3479.4136 - val_acc: 0.5556\n",
      "Epoch 19/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 14.2731 - acc: 0.8301 - val_loss: 3518.7881 - val_acc: 0.5556\n",
      "Epoch 20/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 12.8794 - acc: 0.8235 - val_loss: 3561.7039 - val_acc: 0.5556\n",
      "Epoch 21/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 11.3505 - acc: 0.8301 - val_loss: 3598.8860 - val_acc: 0.5556\n",
      "Epoch 22/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 10.5384 - acc: 0.8431 - val_loss: 3630.9375 - val_acc: 0.5556\n",
      "Epoch 23/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 9.6832 - acc: 0.8431 - val_loss: 3659.3950 - val_acc: 0.5556\n",
      "Epoch 24/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 8.3091 - acc: 0.8562 - val_loss: 3671.2839 - val_acc: 0.5556\n",
      "Epoch 25/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 7.7623 - acc: 0.8627 - val_loss: 3689.7031 - val_acc: 0.5556\n",
      "Epoch 26/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 7.2924 - acc: 0.8693 - val_loss: 3699.9714 - val_acc: 0.5556\n",
      "Epoch 27/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 6.9360 - acc: 0.8627 - val_loss: 3703.8582 - val_acc: 0.5556\n",
      "Epoch 28/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.0894 - acc: 0.8627 - val_loss: 3787.6580 - val_acc: 0.5556\n",
      "Epoch 29/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 6.6930 - acc: 0.8562 - val_loss: 4141.0312 - val_acc: 0.5556\n",
      "Epoch 30/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.7079 - acc: 0.8562 - val_loss: 4145.1470 - val_acc: 0.5556\n",
      "Epoch 31/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 4.8879 - acc: 0.8693 - val_loss: 4124.7310 - val_acc: 0.5556\n",
      "Epoch 32/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 4.9633 - acc: 0.8954 - val_loss: 4038.1106 - val_acc: 0.5556\n",
      "Epoch 33/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 4.6555 - acc: 0.9020 - val_loss: 4022.1194 - val_acc: 0.5556\n",
      "Epoch 34/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 12.4940 - acc: 0.8627 - val_loss: 2559.8330 - val_acc: 0.5556\n",
      "Epoch 35/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 11.5040 - acc: 0.8758 - val_loss: 4153.3779 - val_acc: 0.4444\n",
      "Epoch 36/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 698.4718 - acc: 0.7451 - val_loss: 2664.1870 - val_acc: 0.5000\n",
      "Epoch 37/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 705.3261 - acc: 0.7059 - val_loss: 2810.0369 - val_acc: 0.3889\n",
      "Epoch 38/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 241.9168 - acc: 0.6993 - val_loss: 2315.5186 - val_acc: 0.3889\n",
      "Epoch 39/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 142.7558 - acc: 0.7451 - val_loss: 3444.9385 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 39.5677 - acc: 0.7320 - val_loss: 1105.4076 - val_acc: 0.5556\n",
      "Epoch 41/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 78.2812 - acc: 0.7320 - val_loss: 8741.5791 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 513.0399 - acc: 0.7255 - val_loss: 4642.4883 - val_acc: 0.4444\n",
      "Epoch 43/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2905.2993 - acc: 0.6209 - val_loss: 3607.7930 - val_acc: 0.5556\n",
      "Epoch 44/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 179.0191 - acc: 0.6340 - val_loss: 1238.3696 - val_acc: 0.5556\n",
      "Epoch 45/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 25.0400 - acc: 0.6797 - val_loss: 960.7429 - val_acc: 0.6111\n",
      "Epoch 46/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 19.8998 - acc: 0.6732 - val_loss: 1005.2268 - val_acc: 0.5556\n",
      "Epoch 47/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 5.3995 - acc: 0.6928 - val_loss: 1028.7690 - val_acc: 0.5556\n",
      "Epoch 48/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 3.2449 - acc: 0.6928 - val_loss: 1033.2635 - val_acc: 0.5556\n",
      "Epoch 49/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 2.0850 - acc: 0.6993 - val_loss: 1038.0291 - val_acc: 0.5556\n",
      "Epoch 50/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 1.0984 - acc: 0.6863 - val_loss: 1042.5620 - val_acc: 0.5556\n",
      "Epoch 51/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6547 - acc: 0.7190 - val_loss: 1044.0172 - val_acc: 0.6111\n",
      "Epoch 52/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6470 - acc: 0.6928 - val_loss: 1043.8379 - val_acc: 0.6111\n",
      "Epoch 53/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6457 - acc: 0.7124 - val_loss: 1043.6913 - val_acc: 0.6111\n",
      "Epoch 54/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6512 - acc: 0.6928 - val_loss: 1043.1002 - val_acc: 0.5556\n",
      "Epoch 55/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6371 - acc: 0.6797 - val_loss: 1043.3521 - val_acc: 0.6111\n",
      "Epoch 56/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6400 - acc: 0.6797 - val_loss: 1042.9495 - val_acc: 0.6111\n",
      "Epoch 57/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6376 - acc: 0.6732 - val_loss: 1042.7700 - val_acc: 0.6111\n",
      "Epoch 58/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6368 - acc: 0.7059 - val_loss: 1042.7114 - val_acc: 0.6111\n",
      "Epoch 59/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6363 - acc: 0.6601 - val_loss: 1042.0933 - val_acc: 0.5556\n",
      "Epoch 60/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6377 - acc: 0.6928 - val_loss: 1042.1172 - val_acc: 0.6111\n",
      "Epoch 61/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6339 - acc: 0.6863 - val_loss: 1041.8479 - val_acc: 0.5556\n",
      "Epoch 62/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6342 - acc: 0.6732 - val_loss: 1041.6752 - val_acc: 0.6111\n",
      "Epoch 63/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6333 - acc: 0.7059 - val_loss: 1041.5338 - val_acc: 0.6111\n",
      "Epoch 64/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6294 - acc: 0.6993 - val_loss: 1041.1794 - val_acc: 0.6111\n",
      "Epoch 65/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6365 - acc: 0.6863 - val_loss: 1040.9707 - val_acc: 0.6111\n",
      "Epoch 66/200\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.6278 - acc: 0.6993 - val_loss: 1040.5266 - val_acc: 0.5556\n",
      "Epoch 67/200\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6295 - acc: 0.6797 - val_loss: 1040.3759 - val_acc: 0.5556\n",
      "Epoch 68/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6240 - acc: 0.6863 - val_loss: 1040.1307 - val_acc: 0.5556\n",
      "Epoch 69/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6257 - acc: 0.6993 - val_loss: 1039.8004 - val_acc: 0.5556\n",
      "Epoch 70/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6237 - acc: 0.7059 - val_loss: 1039.5872 - val_acc: 0.5556\n",
      "Epoch 71/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6250 - acc: 0.6863 - val_loss: 1039.1606 - val_acc: 0.5556\n",
      "Epoch 72/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6173 - acc: 0.6863 - val_loss: 1039.2153 - val_acc: 0.5556\n",
      "Epoch 73/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6205 - acc: 0.7059 - val_loss: 1038.7562 - val_acc: 0.5556\n",
      "Epoch 74/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6201 - acc: 0.6732 - val_loss: 1038.3846 - val_acc: 0.5556\n",
      "Epoch 75/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6254 - acc: 0.6863 - val_loss: 1038.6572 - val_acc: 0.6667\n",
      "Epoch 76/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6137 - acc: 0.6928 - val_loss: 1038.0266 - val_acc: 0.5556\n",
      "Epoch 77/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6138 - acc: 0.6797 - val_loss: 1038.2372 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6174 - acc: 0.6863 - val_loss: 1037.5640 - val_acc: 0.5556\n",
      "Epoch 79/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6136 - acc: 0.6863 - val_loss: 1037.2275 - val_acc: 0.5556\n",
      "Epoch 80/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6097 - acc: 0.6863 - val_loss: 1037.5254 - val_acc: 0.6111\n",
      "Epoch 81/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6067 - acc: 0.6863 - val_loss: 1036.8788 - val_acc: 0.5556\n",
      "Epoch 82/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6095 - acc: 0.6928 - val_loss: 1036.7402 - val_acc: 0.5556\n",
      "Epoch 83/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6205 - acc: 0.6732 - val_loss: 1035.7968 - val_acc: 0.5556\n",
      "Epoch 84/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6008 - acc: 0.6928 - val_loss: 1036.2961 - val_acc: 0.6667\n",
      "Epoch 85/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6050 - acc: 0.6732 - val_loss: 1035.9395 - val_acc: 0.6111\n",
      "Epoch 86/200\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6120 - acc: 0.7059 - val_loss: 1035.7534 - val_acc: 0.6111\n",
      "Epoch 87/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6029 - acc: 0.7190 - val_loss: 1035.4578 - val_acc: 0.5556\n",
      "Epoch 88/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6034 - acc: 0.6732 - val_loss: 1034.9399 - val_acc: 0.5556\n",
      "Epoch 89/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6013 - acc: 0.6667 - val_loss: 1034.9136 - val_acc: 0.5556\n",
      "Epoch 90/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6065 - acc: 0.6667 - val_loss: 1034.4293 - val_acc: 0.5556\n",
      "Epoch 91/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5978 - acc: 0.6928 - val_loss: 1034.2031 - val_acc: 0.5556\n",
      "Epoch 92/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5945 - acc: 0.6928 - val_loss: 1033.7681 - val_acc: 0.6111\n",
      "Epoch 93/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5970 - acc: 0.6993 - val_loss: 1034.0171 - val_acc: 0.6111\n",
      "Epoch 94/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5995 - acc: 0.6732 - val_loss: 1033.6987 - val_acc: 0.6111\n",
      "Epoch 95/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5859 - acc: 0.6797 - val_loss: 1032.1202 - val_acc: 0.5556\n",
      "Epoch 96/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6200 - acc: 0.6732 - val_loss: 1033.8214 - val_acc: 0.7778\n",
      "Epoch 97/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5854 - acc: 0.7059 - val_loss: 1032.2534 - val_acc: 0.5556\n",
      "Epoch 98/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5980 - acc: 0.6732 - val_loss: 1032.0271 - val_acc: 0.5556\n",
      "Epoch 99/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5994 - acc: 0.7059 - val_loss: 1032.1832 - val_acc: 0.5556\n",
      "Epoch 100/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6727 - acc: 0.6536 - val_loss: 1033.0925 - val_acc: 0.7222\n",
      "Epoch 101/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6218 - acc: 0.6667 - val_loss: 1032.2192 - val_acc: 0.7222\n",
      "Epoch 102/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5912 - acc: 0.7059 - val_loss: 1030.5222 - val_acc: 0.5556\n",
      "Epoch 103/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5843 - acc: 0.6863 - val_loss: 1030.6309 - val_acc: 0.6111\n",
      "Epoch 104/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5824 - acc: 0.6797 - val_loss: 1030.4323 - val_acc: 0.5556\n",
      "Epoch 105/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5816 - acc: 0.6928 - val_loss: 1029.8221 - val_acc: 0.5556\n",
      "Epoch 106/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6016 - acc: 0.6601 - val_loss: 1029.7654 - val_acc: 0.5556\n",
      "Epoch 107/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5818 - acc: 0.6601 - val_loss: 1029.5154 - val_acc: 0.5556\n",
      "Epoch 108/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5775 - acc: 0.7059 - val_loss: 1028.8794 - val_acc: 0.5556\n",
      "Epoch 109/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5760 - acc: 0.6993 - val_loss: 1029.1700 - val_acc: 0.6111\n",
      "Epoch 110/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5890 - acc: 0.6993 - val_loss: 1028.3569 - val_acc: 0.5556\n",
      "Epoch 111/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5966 - acc: 0.6601 - val_loss: 1027.5999 - val_acc: 0.5556\n",
      "Epoch 112/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5771 - acc: 0.6928 - val_loss: 1028.0707 - val_acc: 0.6111\n",
      "Epoch 113/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5978 - acc: 0.6928 - val_loss: 1028.5841 - val_acc: 0.7222\n",
      "Epoch 114/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5682 - acc: 0.6732 - val_loss: 1027.0837 - val_acc: 0.5000\n",
      "Epoch 115/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5817 - acc: 0.6797 - val_loss: 1027.2488 - val_acc: 0.6111\n",
      "Epoch 116/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5951 - acc: 0.6863 - val_loss: 1026.5453 - val_acc: 0.5556\n",
      "Epoch 117/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5840 - acc: 0.6732 - val_loss: 1025.5083 - val_acc: 0.5556\n",
      "Epoch 118/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5597 - acc: 0.7190 - val_loss: 1027.1569 - val_acc: 0.7778\n",
      "Epoch 119/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5782 - acc: 0.7059 - val_loss: 1026.5896 - val_acc: 0.6111\n",
      "Epoch 120/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5712 - acc: 0.6993 - val_loss: 1025.7196 - val_acc: 0.5556\n",
      "Epoch 121/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5759 - acc: 0.6928 - val_loss: 1024.8711 - val_acc: 0.5556\n",
      "Epoch 122/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5754 - acc: 0.7190 - val_loss: 1025.6093 - val_acc: 0.6111\n",
      "Epoch 123/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5661 - acc: 0.7320 - val_loss: 1026.1255 - val_acc: 0.7222\n",
      "Epoch 124/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6015 - acc: 0.6536 - val_loss: 1025.9065 - val_acc: 0.7222\n",
      "Epoch 125/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5724 - acc: 0.6993 - val_loss: 1024.4969 - val_acc: 0.5556\n",
      "Epoch 126/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5741 - acc: 0.6928 - val_loss: 1024.7505 - val_acc: 0.6111\n",
      "Epoch 127/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5687 - acc: 0.6863 - val_loss: 1025.4071 - val_acc: 0.7222\n",
      "Epoch 128/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5730 - acc: 0.6863 - val_loss: 1025.1249 - val_acc: 0.6667\n",
      "Epoch 129/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6128 - acc: 0.6732 - val_loss: 1024.7336 - val_acc: 0.7222\n",
      "Epoch 130/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5816 - acc: 0.6732 - val_loss: 1023.5819 - val_acc: 0.6111\n",
      "Epoch 131/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5811 - acc: 0.6797 - val_loss: 1023.9556 - val_acc: 0.6667\n",
      "Epoch 132/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5903 - acc: 0.6601 - val_loss: 1022.6491 - val_acc: 0.5556\n",
      "Epoch 133/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5593 - acc: 0.6993 - val_loss: 1023.7983 - val_acc: 0.7222\n",
      "Epoch 134/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5781 - acc: 0.6601 - val_loss: 1021.7446 - val_acc: 0.5556\n",
      "Epoch 135/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5651 - acc: 0.6732 - val_loss: 1022.7970 - val_acc: 0.6111\n",
      "Epoch 136/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5845 - acc: 0.6536 - val_loss: 1022.4488 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5794 - acc: 0.6732 - val_loss: 1022.4311 - val_acc: 0.6111\n",
      "Epoch 138/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5742 - acc: 0.6863 - val_loss: 1021.5980 - val_acc: 0.5556\n",
      "Epoch 139/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5540 - acc: 0.6797 - val_loss: 1020.8229 - val_acc: 0.5556\n",
      "Epoch 140/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5765 - acc: 0.6601 - val_loss: 1022.7820 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5866 - acc: 0.6536 - val_loss: 1022.1511 - val_acc: 0.7222\n",
      "Epoch 142/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5669 - acc: 0.6928 - val_loss: 1020.7151 - val_acc: 0.5556\n",
      "Epoch 143/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5618 - acc: 0.6993 - val_loss: 1020.3602 - val_acc: 0.5556\n",
      "Epoch 144/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5557 - acc: 0.6732 - val_loss: 1019.9092 - val_acc: 0.5556\n",
      "Epoch 145/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5742 - acc: 0.6667 - val_loss: 1020.8680 - val_acc: 0.6667\n",
      "Epoch 146/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5569 - acc: 0.6863 - val_loss: 1021.0359 - val_acc: 0.6667\n",
      "Epoch 147/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5708 - acc: 0.6863 - val_loss: 1020.0985 - val_acc: 0.6111\n",
      "Epoch 148/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5684 - acc: 0.7059 - val_loss: 1020.9900 - val_acc: 0.6667\n",
      "Epoch 149/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5545 - acc: 0.7255 - val_loss: 1021.1709 - val_acc: 0.6667\n",
      "Epoch 150/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5705 - acc: 0.7124 - val_loss: 1019.2643 - val_acc: 0.5556\n",
      "Epoch 151/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5780 - acc: 0.6797 - val_loss: 1019.4866 - val_acc: 0.6667\n",
      "Epoch 152/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5520 - acc: 0.7059 - val_loss: 1017.8983 - val_acc: 0.5556\n",
      "Epoch 153/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5471 - acc: 0.7255 - val_loss: 1017.7679 - val_acc: 0.6111\n",
      "Epoch 154/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5525 - acc: 0.6797 - val_loss: 1018.1847 - val_acc: 0.6111\n",
      "Epoch 155/200\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5531 - acc: 0.7320 - val_loss: 1017.6926 - val_acc: 0.6111\n",
      "Epoch 156/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5615 - acc: 0.6863 - val_loss: 1016.5280 - val_acc: 0.5556\n",
      "Epoch 157/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5608 - acc: 0.6928 - val_loss: 1017.3827 - val_acc: 0.5556\n",
      "Epoch 158/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5741 - acc: 0.6928 - val_loss: 1016.4124 - val_acc: 0.5556\n",
      "Epoch 159/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6160 - acc: 0.6732 - val_loss: 1017.1437 - val_acc: 0.6111\n",
      "Epoch 160/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5657 - acc: 0.6667 - val_loss: 1016.2443 - val_acc: 0.5556\n",
      "Epoch 161/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5497 - acc: 0.7190 - val_loss: 1017.0141 - val_acc: 0.6667\n",
      "Epoch 162/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5484 - acc: 0.7059 - val_loss: 1015.9643 - val_acc: 0.5556\n",
      "Epoch 163/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5648 - acc: 0.6928 - val_loss: 1017.6953 - val_acc: 0.6111\n",
      "Epoch 164/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6024 - acc: 0.6732 - val_loss: 1014.9803 - val_acc: 0.5556\n",
      "Epoch 165/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5915 - acc: 0.6928 - val_loss: 1015.3638 - val_acc: 0.5556\n",
      "Epoch 166/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5422 - acc: 0.6928 - val_loss: 1017.0289 - val_acc: 0.6111\n",
      "Epoch 167/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5572 - acc: 0.7516 - val_loss: 1016.7551 - val_acc: 0.6111\n",
      "Epoch 168/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5560 - acc: 0.7124 - val_loss: 1019.5759 - val_acc: 0.6667\n",
      "Epoch 169/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5744 - acc: 0.6797 - val_loss: 1016.5139 - val_acc: 0.6111\n",
      "Epoch 170/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5425 - acc: 0.6928 - val_loss: 1015.0098 - val_acc: 0.5556\n",
      "Epoch 171/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5855 - acc: 0.6993 - val_loss: 1017.7356 - val_acc: 0.6667\n",
      "Epoch 172/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5701 - acc: 0.6732 - val_loss: 1016.0875 - val_acc: 0.6111\n",
      "Epoch 173/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5514 - acc: 0.6928 - val_loss: 1017.2386 - val_acc: 0.6667\n",
      "Epoch 174/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5638 - acc: 0.6667 - val_loss: 1016.0151 - val_acc: 0.5556\n",
      "Epoch 175/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5503 - acc: 0.7059 - val_loss: 1016.8821 - val_acc: 0.6111\n",
      "Epoch 176/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5617 - acc: 0.6863 - val_loss: 1017.0289 - val_acc: 0.6111\n",
      "Epoch 177/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.6307 - acc: 0.6601 - val_loss: 1016.4675 - val_acc: 0.6111\n",
      "Epoch 178/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5568 - acc: 0.6732 - val_loss: 1016.2778 - val_acc: 0.6111\n",
      "Epoch 179/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5701 - acc: 0.7124 - val_loss: 1015.5103 - val_acc: 0.5556\n",
      "Epoch 180/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5690 - acc: 0.6601 - val_loss: 1018.6069 - val_acc: 0.6667\n",
      "Epoch 181/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5861 - acc: 0.7124 - val_loss: 1018.1021 - val_acc: 0.6667\n",
      "Epoch 182/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5683 - acc: 0.6797 - val_loss: 1016.7307 - val_acc: 0.5556\n",
      "Epoch 183/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5479 - acc: 0.6928 - val_loss: 1018.3542 - val_acc: 0.6667\n",
      "Epoch 184/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5608 - acc: 0.6928 - val_loss: 1017.7831 - val_acc: 0.6111\n",
      "Epoch 185/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5613 - acc: 0.6797 - val_loss: 1017.2771 - val_acc: 0.5556\n",
      "Epoch 186/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5751 - acc: 0.7190 - val_loss: 1020.7521 - val_acc: 0.6667\n",
      "Epoch 187/200\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.5910 - acc: 0.6732 - val_loss: 1018.9648 - val_acc: 0.6667\n",
      "Epoch 188/200\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5547 - acc: 0.7386 - val_loss: 1018.2274 - val_acc: 0.5556\n",
      "Epoch 189/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5356 - acc: 0.7516 - val_loss: 1022.4947 - val_acc: 0.6667\n",
      "Epoch 190/200\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.6210 - acc: 0.7059 - val_loss: 1018.4738 - val_acc: 0.5556\n",
      "Epoch 191/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6582 - acc: 0.6471 - val_loss: 1020.2599 - val_acc: 0.5556\n",
      "Epoch 192/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6415 - acc: 0.7059 - val_loss: 1025.6584 - val_acc: 0.6667\n",
      "Epoch 193/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5695 - acc: 0.7255 - val_loss: 1023.1057 - val_acc: 0.5556\n",
      "Epoch 194/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5616 - acc: 0.7124 - val_loss: 1023.0167 - val_acc: 0.5556\n",
      "Epoch 195/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5589 - acc: 0.7059 - val_loss: 1022.7861 - val_acc: 0.5556\n",
      "Epoch 196/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5933 - acc: 0.6993 - val_loss: 1027.8219 - val_acc: 0.6667\n",
      "Epoch 197/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.7384 - acc: 0.7124 - val_loss: 1024.9934 - val_acc: 0.5556\n",
      "Epoch 198/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.7858 - acc: 0.6797 - val_loss: 1031.6334 - val_acc: 0.6667\n",
      "Epoch 199/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6349 - acc: 0.7059 - val_loss: 1031.3915 - val_acc: 0.6667\n",
      "Epoch 200/200\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5402 - acc: 0.6928 - val_loss: 1032.6168 - val_acc: 0.6667\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ae5aa00f08>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(\n",
    "    [x_train, A_train],\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}