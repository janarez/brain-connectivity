{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "9c40931cbb4a31228df7bc840fc8745c5509fc7c9b0d60dae36a005e5fe0dba9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GIN < FC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "import numpy as np\r\n",
    "import pickle\r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from enum import Enum, auto\r\n",
    "import typing\r\n",
    "from typing import List, Union\r\n",
    "import copy\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "from torch_geometric.nn import GINConv, global_add_pool\r\n",
    "from torch_geometric.data import Data, DataLoader\r\n",
    "\r\n",
    "from torchinfo import summary\r\n",
    "from sklearn.model_selection import StratifiedKFold"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "DATA_FOLDER = '../data'\r\n",
    "PICKLE_FOLDER = '../pickles'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_metadata = pd.read_csv(f'{DATA_FOLDER}/patients-cleaned.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_metadata.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  target\n",
       "0  24.750    1       0\n",
       "1  27.667    1       0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select connectivity dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "THRESHOLD = 0.1                                          # 0.01, 0.05, 0.1, 0.15\r\n",
    "N = 20                                                   # 3, 5, 7, 10, 15, 20, 40\r\n",
    "CORR_TYPE = 'pearson'                                    # 'pearson', 'spearman', 'partial-pearson'\r\n",
    "THRESHOLD_METHOD = 'abs-group-avg-diff'                  # 'abs-sample-diff', 'abs-group-avg-diff'\r\n",
    "THRESHOLD_TYPE = 'max'                                   # 'min', 'max' or for kNN 'small', 'large'\r\n",
    "KNN = False                                              # Whether all or only top N neigbors are taken"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "fc_folder = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}{\"-knn\" if KNN else \"\"}-{THRESHOLD_METHOD}'\r\n",
    "\r\n",
    "# Try Gini or SGD.\r\n",
    "# fc_folder = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}-gini'\r\n",
    "# fc_folder = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}-sgd'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "fc_file_binary = f'{fc_folder}/{THRESHOLD_TYPE}-{f\"knn-{N}\" if KNN else f\"th-{THRESHOLD}\"}-binary.pickle'\r\n",
    "fc_file_real = f'{fc_folder}/{THRESHOLD_TYPE}-{f\"knn-{N}\" if KNN else f\"th-{THRESHOLD}\"}-real.pickle'\r\n",
    "\r\n",
    "# fc_file_binary = f'{fc_folder}/binary.pickle'\r\n",
    "# fc_file_real = f'{fc_folder}/real.pickle'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "with open(fc_file_binary, 'rb') as f:\r\n",
    "    edge_index_matrix = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "with open(fc_file_real, 'rb') as f:\r\n",
    "    fc_matrix = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "total_samples, total_brain_regions, _ = edge_index_matrix.shape\r\n",
    "edge_index_matrix.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(190, 90, 90)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "fc_matrix.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(190, 90, 90)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "with open(f'{PICKLE_FOLDER}/test-indices.pickle', 'rb') as f:\r\n",
    "    test_indices = pickle.load(f)\r\n",
    "    \r\n",
    "train_indices = list(set(range(total_samples)) - set(test_indices))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_targets = df_metadata.iloc[train_indices][\"target\"].reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(f'Train set size: {len(train_indices)}')\r\n",
    "print(f'Test set size: {len(test_indices)}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set size: 140\n",
      "Test set size: 50\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Data` object fields\r\n",
    "\r\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\r\n",
    "\r\n",
    "- `data.edge_index`: Graph connectivity in COO format with shape `[2, num_edges]` and type `torch.long`\r\n",
    "\r\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\r\n",
    "\r\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\r\n",
    "\r\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select node features\r\n",
    "\r\n",
    "- onehot\r\n",
    "- correlations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Each nodes contains its row from FC matrix.\r\n",
    "def correlations_in_nodes(i):\r\n",
    "    return torch.from_numpy(fc_matrix[i]).to(torch.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Each brain region is onehot encoded. See GIN for phenotype paper.\r\n",
    "def onehot_in_nodes(i):\r\n",
    "    return torch.diag(torch.ones(total_brain_regions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "features_in_nodes = correlations_in_nodes\r\n",
    "num_features_in_nodes = total_brain_regions   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "dataset = [Data(\r\n",
    "    x=features_in_nodes(i),  \r\n",
    "    edge_index=torch.from_numpy(np.asarray(np.nonzero(edge_index_matrix[i]))).to(torch.int64),\r\n",
    "    # y=torch.tensor([[1, 0]]  if target == 0 else [[0, 1]], dtype=torch.int64)\r\n",
    "    y=torch.tensor([target], dtype=torch.int64)\r\n",
    ").to(device) for target, i in zip(train_targets, train_indices)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "print(f'True train data: {len(dataset)}')\r\n",
    "\r\n",
    "print('Data object')\r\n",
    "print(f'Edge index: {dataset[0].edge_index.shape}')\r\n",
    "print(f'Node features: {dataset[0].x.shape}')\r\n",
    "print(f'Target: {dataset[0].y.shape}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True train data: 140\n",
      "Data object\n",
      "Edge index: torch.Size([2, 7716])\n",
      "Node features: torch.Size([90, 90])\n",
      "Target: torch.Size([1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define GIN < FC architectures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "class ConnectivityEmbedding(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Learns connectivity between nodes. For each node a weighted combination of all the nodes is learned.\r\n",
    "\r\n",
    "    Input: [batch_size, num_nodes, num_features]\r\n",
    "    Output: [batch_size, num_nodes, num_features]\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, size, dropout: 0.0):\r\n",
    "        super(ConnectivityEmbedding, self).__init__()\r\n",
    "        # Initialize with fully connected graph.\r\n",
    "        self.fc_matrix = nn.Parameter(torch.ones(size, size), requires_grad=True)\r\n",
    "        self.dropout = nn.Dropout(p=dropout)\r\n",
    "\r\n",
    "    def toggle_gradients(self, requires_grad):\r\n",
    "        self.fc_matrix.requires_grad = requires_grad\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # There is no non-linearity since we are just combining nodes.\r\n",
    "        return self.dropout(torch.matmul(self.fc_matrix, x))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "class ConnectivityMLP(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Runs node features through MLP.\r\n",
    "\r\n",
    "    Input: [batch_size, num_nodes, num_in_features]\r\n",
    "    Output: [batch_size, num_nodes, num_out_features]\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, size_in, size_out, dropout):\r\n",
    "        super(ConnectivityMLP, self).__init__()\r\n",
    "        self.fc = nn.Linear(size_in, size_out)\r\n",
    "        self.dropout = nn.Dropout(p=dropout)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        return F.relu(self.dropout(self.fc(x)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "class ConnectivityMode(Enum):\r\n",
    "    \"\"\"\r\n",
    "    Determines how is connectivity matrix obtained.\r\n",
    "\r\n",
    "    FIXED: Use handmade FC matrix.\r\n",
    "    START: Learn FC matrix only on raw input features.\r\n",
    "    SINGLE: Learn FC matrix on raw input features as well as all subsequent feature mapping layers.\r\n",
    "    MULTIPLE: Learn new FC matrix before every feature mapping layer.\r\n",
    "    \"\"\"\r\n",
    "    FIXED = auto()\r\n",
    "    START = auto()\r\n",
    "    SINGLE = auto()\r\n",
    "    MULTIPLE = auto()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "class ConnectivitySublayer(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Combines neighborhood connectivity with MLP transformation.\r\n",
    "\r\n",
    "    Input: [batch_size, num_nodes, num_in_features]\r\n",
    "    Output: [batch_size, num_nodes, num_out_features]\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, id: int, size_in: int, size_out: int, dropout: float, mode: ConnectivityMode, **mode_kwargs):\r\n",
    "        super(ConnectivitySublayer, self).__init__()\r\n",
    "        # Create new FC matrix for this sublayer.\r\n",
    "        if mode == ConnectivityMode.MULTIPLE:\r\n",
    "            self.fc_matrix = ConnectivityEmbedding(size_in, dropout=mode_kwargs['dropout'])\r\n",
    "        # Used passed in FC matrix.\r\n",
    "        else:\r\n",
    "            self.fc_matrix = mode_kwargs['fc_matrix']\r\n",
    "\r\n",
    "        # Feature mapping layer.\r\n",
    "        self.mlp = ConnectivityMLP(size_in, size_out, dropout)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # Aggregate feature vectors based on connectivity neighborhood.\r\n",
    "        x = self.fc_matrix(x)\r\n",
    "        # Map features.\r\n",
    "        x = self.mlp(x)\r\n",
    "        return x       \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "class ConnectivityDenseNet(nn.Module):\r\n",
    "    \"\"\"\r\n",
    "    Emulates Graph isomorphism network using a fully connected alternative.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(\r\n",
    "        self, \r\n",
    "        num_nodes: int, \r\n",
    "        mode: ConnectivityMode, \r\n",
    "        num_in_features: int, \r\n",
    "        num_hidden_features: Union[int, List[int]],\r\n",
    "        dropout: float = 0.5,\r\n",
    "        connectivity_dropout: float = 0.0, \r\n",
    "        num_sublayers: int = -1,\r\n",
    "        readout: str = 'add', \r\n",
    "        **mode_kwargs\r\n",
    "    ):\r\n",
    "        super(ConnectivityDenseNet, self).__init__()\r\n",
    "\r\n",
    "        self.fc_matrix = None\r\n",
    "        # Set passed in FC matrix.\r\n",
    "        if mode == ConnectivityMode.FIXED:\r\n",
    "            self.fc_matrix = mode_kwargs['fc_matrix']\r\n",
    "        # Create single FC matrix that will be learned only at the beggining.\r\n",
    "        # or\r\n",
    "        # Create single FC matrix that will be learned throughout.\r\n",
    "        elif (mode == ConnectivityMode.START) or (mode == ConnectivityMode.SINGLE):\r\n",
    "            self.fc_matrix = ConnectivityEmbedding(num_nodes, dropout=connectivity_dropout)\r\n",
    "        # Else `ConnectivityMode.MULTIPLE`, let each sublayer create its own FC matrix.\r\n",
    "        self.mode_kwargs = {\r\n",
    "            'fc_matrix': self.fc_matrix,\r\n",
    "            'dropout': connectivity_dropout\r\n",
    "        }\r\n",
    "\r\n",
    "        # Prepare feature mapping dimensions.\r\n",
    "        if type(num_hidden_features) is int:\r\n",
    "            num_out_features = np.repeat(num_hidden_features, num_sublayers)\r\n",
    "        num_in_features = copy.copy(num_out_features)\r\n",
    "        num_out_features[0] = num_nodes\r\n",
    "\r\n",
    "        # Create model stacked from sublayers: connectivity + feature mapping.\r\n",
    "        self.sublayers = nn.ModuleList([\r\n",
    "            ConnectivitySublayer(\r\n",
    "                size_in, size_out, dropout=dropout, mode=mode, mode_kwargs=self.mode_kwargs\r\n",
    "            ) for size_in, size_out in zip(num_in_features, num_out_features)\r\n",
    "        ])\r\n",
    "\r\n",
    "        # Classification head.\r\n",
    "        self.readout = readout\r\n",
    "        self.fc = nn.Linear(num_out_features[-1], 2)\r\n",
    "        \r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        # Run sample through model.\r\n",
    "        for sublayer in self.sublayers:\r\n",
    "            x = sublayer(x)\r\n",
    "\r\n",
    "        # Binary classification head.\r\n",
    "        # Readout across nodes.\r\n",
    "        if self.readout == 'add':\r\n",
    "            x = torch.sum(x, dim=1)\r\n",
    "        elif self.readout == 'mean':\r\n",
    "            x = torch.mean(x, dim=1)\r\n",
    "        if self.readout == 'max':\r\n",
    "            x = torch.max(x, dim=1)\r\n",
    "\r\n",
    "        # Return binary logits.\r\n",
    "        return self.fc(x)\r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "class MLP(torch.nn.Module):\r\n",
    "    def __init__(self, inchan, outchan):\r\n",
    "        super(MLP, self).__init__()\r\n",
    "        \r\n",
    "        self.fc = Linear(inchan, outchan)\r\n",
    "        self.activation = ReLU()\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        x = self.activation(self.fc(x))\r\n",
    "        \r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "class GIN(torch.nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, depth, hidchan=total_brain_regions, eps=0.):\r\n",
    "        super(GIN, self).__init__()\r\n",
    "\r\n",
    "        self.convs = torch.nn.ModuleList([GINConv(MLP(hidchan, hidchan), eps=eps) for _ in range(depth)])\r\n",
    "        self.final_fc = Linear(hidchan, 2)\r\n",
    "\r\n",
    "    def forward(self, data):\r\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\r\n",
    "\r\n",
    "        # Message passing.\r\n",
    "        for conv in self.convs:\r\n",
    "            x = conv(x, edge_index)\r\n",
    "\r\n",
    "        # Readout.\r\n",
    "        x = global_add_pool(x, batch)\r\n",
    "\r\n",
    "        # Final FC.\r\n",
    "        x = self.final_fc(x)\r\n",
    "        \r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Architecture FC.\r\n",
    "# summary(FC(depth=3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Architecture GIN.\r\n",
    "summary(GIN(depth=3))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "GIN                                      --\n",
       "├─ModuleList: 1-1                        --\n",
       "│    └─GINConv: 2-1                      --\n",
       "│    │    └─MLP: 3-1                     8,190\n",
       "│    └─GINConv: 2-2                      --\n",
       "│    │    └─MLP: 3-2                     8,190\n",
       "│    └─GINConv: 2-3                      --\n",
       "│    │    └─MLP: 3-3                     8,190\n",
       "├─Linear: 1-2                            182\n",
       "=================================================================\n",
       "Total params: 24,752\n",
       "Trainable params: 24,752\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def evaluation_metrics(predicted, labels):\r\n",
    "    pred_positives = predicted == 1\r\n",
    "    label_positives = labels == 1\r\n",
    "\r\n",
    "    tp = (pred_positives & label_positives).sum().item()\r\n",
    "    tn = (~pred_positives & ~label_positives).sum().item()\r\n",
    "    fp = (pred_positives & ~label_positives).sum().item()\r\n",
    "    fn = (~pred_positives & label_positives).sum().item()\r\n",
    "\r\n",
    "    return tp, tn, fp, fn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "NUM_FOLDS = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, random_state=42, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Settings.\r\n",
    "EPOCHS = 200\r\n",
    "LR = 0.001\r\n",
    "MOMENTUM = 0.5\r\n",
    "OPTIMIZER = 'adam'\r\n",
    "LOSS = 'ce'\r\n",
    "BATCH_SIZE = 2\r\n",
    "\r\n",
    "VALIDATE_FREQ = 10\r\n",
    "\r\n",
    "DEPTH = 3\r\n",
    "EPS = 0.2\r\n",
    "\r\n",
    "STEP_SIZE = 50\r\n",
    "GAMMA = 0.5\r\n",
    "\r\n",
    "WEIGHT_DECAY = 0.0001\r\n",
    "\r\n",
    "settings_str = f'bs={BATCH_SIZE},e={EPOCHS},lr={LR},mom={MOMENTUM},opt={OPTIMIZER},loss={LOSS},step={STEP_SIZE},gamma={GAMMA},wd={WEIGHT_DECAY},eps={EPS}'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Experiment folder.\r\n",
    "EXP_FOLDER = 'runs/fc-vs-gin'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Experiment.\r\n",
    "EXP_ID = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "for kfold, (train_index, val_index) in enumerate(skf.split(np.zeros(len(train_targets)), train_targets)):\r\n",
    "\r\n",
    "    # Init TB writer.\r\n",
    "    experiment_str = f'id={EXP_ID:03d},fold={kfold},{settings_str}'\r\n",
    "    writer_FC = SummaryWriter(f\"../{EXP_FOLDER}/FC/{experiment_str}\")\r\n",
    "    writer_GIN = SummaryWriter(f\"../{EXP_FOLDER}/GIN/{experiment_str}\")\r\n",
    "\r\n",
    "    # Init models.\r\n",
    "    net_GIN = GIN(depth=DEPTH, eps=EPS).to(device)\r\n",
    "    optimizr_GIN = torch.optim.Adam(net_GIN.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\r\n",
    "    criterion_GIN = torch.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "    net_FC = FC(depth=DEPTH).to(device)\r\n",
    "    optimizr_FC = torch.optim.Adam(net_FC.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\r\n",
    "    criterion_FC = torch.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "    # Save architecture.\r\n",
    "    with open(f\"../{EXP_FOLDER}/GIN/{experiment_str}/architecture\", 'w', encoding=\"utf-8\") as f:\r\n",
    "        f.write(fc_folder + '\\n')\r\n",
    "        f.write(fc_file_binary + '\\n')\r\n",
    "        f.write(fc_file_real + '\\n')\r\n",
    "        f.write(features_in_nodes.__str__() + '\\n')\r\n",
    "        f.write('\\n'.join(experiment_str.split(',')) + '\\n\\n')\r\n",
    "        f.write(net_FC.__str__() + '\\n\\n')\r\n",
    "        f.write(net_GIN.__str__() + '\\n\\n')\r\n",
    "        f.write(str(summary(net_FC)))\r\n",
    "        f.write(str(summary(net_GIN)))\r\n",
    "\r\n",
    "    # Prepare data.\r\n",
    "    X_train = [dataset[i] for i in train_index]\r\n",
    "    X_val = [dataset[i] for i in val_index]\r\n",
    "    \r\n",
    "    trainloader = DataLoader(X_train, batch_size=BATCH_SIZE, shuffle=True)\r\n",
    "    valloader = DataLoader(X_val, batch_size=BATCH_SIZE, shuffle=False)\r\n",
    "\r\n",
    "    # Train.\r\n",
    "    for epoch in range(EPOCHS):\r\n",
    "        running_loss_GIN = 0.\r\n",
    "        running_loss_FC = 0.\r\n",
    "        \r\n",
    "        net_FC.train()\r\n",
    "        net_GIN.train()\r\n",
    "\r\n",
    "        for data in trainloader:\r\n",
    "            \r\n",
    "            optimizr_GIN.zero_grad()\r\n",
    "            optimizr_FC.zero_grad()\r\n",
    "\r\n",
    "            outputs_GIN = net_GIN(data)\r\n",
    "            outputs_FC = net_FC(data)\r\n",
    "\r\n",
    "            loss_GIN = criterion_GIN(outputs_GIN, data.y)\r\n",
    "            loss_FC = criterion_FC(outputs_FC, data.y)\r\n",
    "\r\n",
    "            loss_GIN.backward()\r\n",
    "            loss_FC.backward()\r\n",
    "\r\n",
    "            optimizr_GIN.step()\r\n",
    "            optimizr_FC.step()\r\n",
    "\r\n",
    "            running_loss_GIN += loss_GIN.item()\r\n",
    "            running_loss_FC += loss_FC.item()\r\n",
    "\r\n",
    "        epoch_loss_GIN = running_loss_GIN / len(trainloader)\r\n",
    "        epoch_loss_FC = running_loss_FC / len(trainloader)\r\n",
    "\r\n",
    "        writer_GIN.add_scalar('training loss', epoch_loss_GIN, epoch)\r\n",
    "        writer_FC.add_scalar('training loss', epoch_loss_FC, epoch)\r\n",
    "\r\n",
    "        running_loss_GIN = 0.\r\n",
    "        running_loss_FC = 0.\r\n",
    "\r\n",
    "        # Evaluate epoch.\r\n",
    "        tp_GIN, tn_GIN, fp_GIN, fn_GIN = 0, 0, 0, 0\r\n",
    "        tp_FC, tn_FC, fp_FC, fn_FC = 0, 0, 0, 0\r\n",
    "        total = 0\r\n",
    "\r\n",
    "        net_GIN.eval()\r\n",
    "        net_FC.eval()\r\n",
    "        for data in valloader:\r\n",
    "            optimizr_GIN.zero_grad()\r\n",
    "            optimizr_FC.zero_grad()\r\n",
    "\r\n",
    "            outputs_GIN = net_GIN(data)\r\n",
    "            outputs_FC = net_GIN(data)\r\n",
    "\r\n",
    "            loss_GIN = criterion_GIN(outputs_GIN, data.y)\r\n",
    "            loss_FC = criterion_FC(outputs_FC, data.y)\r\n",
    "\r\n",
    "            running_loss_GIN += loss_GIN.item()\r\n",
    "            running_loss_FC += loss_FC.item()\r\n",
    "\r\n",
    "            if (epoch+1) % VALIDATE_FREQ == 0:\r\n",
    "                predicted_GIN = outputs_GIN.argmax(dim=1)\r\n",
    "                predicted_FC = outputs_FC.argmax(dim=1)\r\n",
    "\r\n",
    "                # labels = torch.nonzero(data.y, as_tuple=True)[1]\r\n",
    "                labels = data.y.view(-1)\r\n",
    "\r\n",
    "                # Update.\r\n",
    "                _tp_GIN, _tn_GIN, _fp_GIN, _fn_GIN = evaluation_metrics(predicted_GIN, labels)\r\n",
    "                _tp_FC, _tn_FC, _fp_FC, _fn_FC = evaluation_metrics(predicted_FC, labels)\r\n",
    "\r\n",
    "                tp_GIN += _tp_GIN; tn_GIN += _tn_GIN; fp_GIN += _fp_GIN; fn_GIN += _fn_GIN\r\n",
    "                tp_FC += _tp_FC; tn_FC += _tn_FC; fp_FC += _fp_FC; fn_FC += _fn_FC\r\n",
    "\r\n",
    "                total += data.y.size(0)\r\n",
    "\r\n",
    "        epoch_loss_GIN = running_loss_GIN / len(valloader)\r\n",
    "        epoch_loss_FC = running_loss_FC / len(valloader)\r\n",
    "\r\n",
    "        writer_GIN.add_scalar('validation loss', epoch_loss_GIN, epoch)\r\n",
    "        writer_FC.add_scalar('validation loss', epoch_loss_FC, epoch)\r\n",
    "\r\n",
    "        if (epoch+1) % VALIDATE_FREQ == 0:\r\n",
    "            writer_GIN.add_scalar('validation accuracy', (tp_GIN + tn_GIN) / total, epoch)\r\n",
    "            writer_GIN.add_scalar('validation precision', tp_GIN / (tp_GIN + fp_GIN) if (tp_GIN + fp_GIN) > 0 else 0, epoch)\r\n",
    "            writer_GIN.add_scalar('validation recall', tp_GIN / (tp_GIN + fn_GIN), epoch)\r\n",
    "    \r\n",
    "            writer_FC.add_scalar('validation accuracy', (tp_FC + tn_FC) / total, epoch)\r\n",
    "            writer_FC.add_scalar('validation precision', tp_FC / (tp_FC + fp_FC) if (tp_FC + fp_FC) > 0 else 0, epoch)\r\n",
    "            writer_FC.add_scalar('validation recall', tp_FC / (tp_FC + fn_FC), epoch)\r\n",
    "\r\n",
    "    # Single fold during exploration.\r\n",
    "    #break\r\n",
    "\r\n",
    "print('Finished training')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-fd6f5f7242e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0moutputs_GIN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_GIN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0moutputs_FC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_FC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mloss_GIN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_GIN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_GIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\brain-connectivity\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-a66f303c0206>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_fc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_fcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Global add pool equivalent.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-a66f303c0206>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_fc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_fcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Global add pool equivalent.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\brain-connectivity\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-17c785e89da7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\brain-connectivity\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\brain-connectivity\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janar\\Documents\\MFF\\DiplomaThesis\\BrainConnectivityMachineLearning\\brain-connectivity\\.venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}