{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import os\n",
    "import torch\n",
    "import operator\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from brain_connectivity import (\n",
    "    dataset,\n",
    "    gin,\n",
    "    dense,\n",
    "    enums,\n",
    "    training,\n",
    "    evaluation,\n",
    "    general_utils,\n",
    "    data_utils,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_hyperparameters = {\n",
    "    # Dataset.\n",
    "    \"upsample_ts\": [None],\n",
    "    \"upsample_ts_method\": [\"iaaft\"],\n",
    "    \"correlation_type\": [enums.CorrelationType.PEARSON],\n",
    "    \"batch_size\": [2, 4, 8],\n",
    "    # Model.\n",
    "    'num_hidden_features': [8, 16, 32, 64, 90],\n",
    "    'num_sublayers': [1, 2],\n",
    "    'dropout': [0.0, 0.5],\n",
    "    # Training.\n",
    "    'optimizer_kwargs': {\n",
    "        'lr': [0.01, 0.001, 0.0001],\n",
    "        'weight_decay': [0.0001]\n",
    "    },\n",
    "    'epochs': [20],\n",
    "}\n",
    "\n",
    "graph_hyperparameters_fixed = {\n",
    "    \"node_features\": [enums.NodeFeatures.FC_MATRIX_ROW],\n",
    "    # How to create FC matrix.\n",
    "    \"geometric_kwargs\": {\n",
    "        \"thresholding_function\": [enums.ThresholdingFunction.GROUP_AVERAGE, enums.ThresholdingFunction.SUBJECT_VALUES],\n",
    "        \"threshold_type\": [enums.DataThresholdingType.FIXED_THRESHOLD],\n",
    "        \"threshold\": [0.01, 0.05, 0.1],\n",
    "        # FIXME: Cannot name file with `str` of `operator` function due to \"<>\".\n",
    "        # \"thresholding_operator\": [operator.ge],\n",
    "        \"threshold_by_absolute_value\": [True, False],\n",
    "        \"return_absolute_value\": [False],\n",
    "    },\n",
    "    \"eps\": [0.0]\n",
    "}\n",
    "graph_hyperparameters_fixed.update(common_hyperparameters)\n",
    "\n",
    "graph_hyperparameters_knn = copy.deepcopy(graph_hyperparameters_fixed)\n",
    "graph_hyperparameters_knn[\"geometric_kwargs\"][\"threshold_type\"] = [enums.DataThresholdingType.KNN]\n",
    "graph_hyperparameters_knn[\"geometric_kwargs\"][\"threshold\"] = [5, 10, 20]\n",
    "graph_hyperparameters = [graph_hyperparameters_fixed, graph_hyperparameters_knn]\n",
    "\n",
    "dense_hyperparameters = {\n",
    "    \"node_features\": [enums.NodeFeatures.FC_MATRIX_ROW],\n",
    "    \"mode\": [enums.ConnectivityMode.SINGLE],\n",
    "    \"num_nodes\": [90],\n",
    "    \"readout\": [\"add\", \"mean\", \"max\"],\n",
    "    \"emb_dropout\": [0.0],\n",
    "    \"emb_residual\": [None, \"add\", \"mean\", \"max\"],\n",
    "    \"emb_init_weights\": [\"constant\", \"normal\"],\n",
    "    \"emb_val\": [0.0],\n",
    "    \"emb_std\": [0.01],\n",
    "}\n",
    "dense_hyperparameters.update(common_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always fixed parameters.\n",
    "model_params = {\n",
    "    \"size_in\": 90\n",
    "}\n",
    "dataset_params = {\n",
    "    # Raw data.\n",
    "    \"data_folder\": os.path.normpath('../data'),\n",
    "    \"device\": device,\n",
    "}\n",
    "training_params = {\n",
    "    # Training regime.\n",
    "    'validation_frequency': 1,\n",
    "    \n",
    "    # Optimizer.\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    # Loss.\n",
    "    'criterion': torch.nn.CrossEntropyLoss(),\n",
    "    # Scheduler.\n",
    "    # 'scheduler': torch.optim.lr_scheduler.StepLR,\n",
    "    # 'scheduler_kwargs': {\n",
    "    #     'step_size': 50,\n",
    "    #     'gamma': 0.5\n",
    "    # },\n",
    "\n",
    "    # Plotting.\n",
    "    'fc_matrix_plot_frequency': None,\n",
    "    'fc_matrix_plot_sublayer': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = data_utils.DoubleLevelParameterGrid(graph_hyperparameters)\n",
    "len(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_with_subjects = \"patients-cleaned.csv\"\n",
    "target_column = \"target\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(os.path.normpath(\"../data\"), dataframe_with_subjects),\n",
    "    index_col=0,\n",
    ")\n",
    "targets = df[target_column].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dataset)\n",
    "reload(gin)\n",
    "reload(dense)\n",
    "reload(evaluation)\n",
    "reload(training)\n",
    "reload(data_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = os.path.join(os.path.normpath(\"../runs\"), f\"test_gin_{i}\")\n",
    "os.makedirs(experiment_folder, exist_ok=False)\n",
    "\n",
    "i += 1\n",
    "general_utils.close_all_loggers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init cross-validation.\n",
    "num_assess_folds = 2\n",
    "num_select_folds = 3\n",
    "cv = data_utils.StratifiedCrossValidation(\n",
    "    targets=targets,\n",
    "    num_assess_folds=num_assess_folds,\n",
    "    num_select_folds=num_select_folds,\n",
    ")\n",
    "\n",
    "for outer_id in cv.outer_cross_validation():\n",
    "    os.makedirs(os.path.join(experiment_folder, f\"{outer_id:03d}\"), exist_ok=False)\n",
    "    logger = general_utils.get_logger(\n",
    "            \"cv\", os.path.join(experiment_folder, f\"{outer_id:03d}\", \"cv.txt\")\n",
    "        )\n",
    "    # Model selection.\n",
    "    # Keep best hyperparameters.\n",
    "    best_hyperparameters = None\n",
    "    best_mean_accuracy = 0\n",
    "    best_std_accuracy = 0\n",
    "\n",
    "    hyperparameter_grid = data_utils.DoubleLevelParameterGrid(\n",
    "        graph_hyperparameters\n",
    "    )\n",
    "    for hyper_id, hyperparameters in enumerate(hyperparameter_grid):\n",
    "        logger.info(f\"Hyperparameters: {hyperparameters}\")\n",
    "        if hyper_id == 2:\n",
    "            break\n",
    "        log_folder = os.path.join(\n",
    "            experiment_folder,\n",
    "            f\"{outer_id:03d}\",\n",
    "            f\"{hyper_id:04d}_{training.stringify(hyperparameters)}\",\n",
    "        )\n",
    "        os.makedirs(log_folder, exist_ok=False)\n",
    "\n",
    "        model, data, trainer = training.init_geometric_traning(\n",
    "            log_folder,\n",
    "            device,\n",
    "            hyperparameters,\n",
    "            targets,\n",
    "            model_params=model_params,\n",
    "            dataset_params=dataset_params,\n",
    "            training_params=training_params,\n",
    "        )\n",
    "\n",
    "        # Run training.\n",
    "        train_dataset = \"train\"\n",
    "        eval_dataset = \"val\"\n",
    "        for inner_id in cv.inner_cross_validation():\n",
    "            logger.debug(f\"Inner fold {inner_id+1} / {num_select_folds}\")\n",
    "            trainer.train(\n",
    "                model=model,\n",
    "                named_trainloader=(\n",
    "                    train_dataset,\n",
    "                    data.geometric_loader(\n",
    "                        dataset=train_dataset, indices=cv.train_indices\n",
    "                    ),\n",
    "                ),\n",
    "                named_evalloader=(\n",
    "                    eval_dataset,\n",
    "                    data.geometric_loader(\n",
    "                        dataset=eval_dataset, indices=cv.val_indices\n",
    "                    ),\n",
    "                ),\n",
    "                fold=inner_id,\n",
    "            )\n",
    "\n",
    "        # Results.\n",
    "        train_results, eval_results = trainer.get_results(\n",
    "            train_dataset=train_dataset, eval_dataset=eval_dataset\n",
    "        )\n",
    "        logger.debug(f\"Train: {train_results}\")\n",
    "        logger.debug(f\"Val: {eval_results}\")\n",
    "\n",
    "        # Update best setting based on eval accuracy\n",
    "        max_index = np.argmax(\n",
    "            eval_results[\"accuracy\"][0] - eval_results[\"accuracy\"][1]\n",
    "        )\n",
    "        max_mean_accuracy = eval_results[\"accuracy\"][0][max_index]\n",
    "        max_std_accuracy = eval_results[\"accuracy\"][1][max_index]\n",
    "\n",
    "        if (max_mean_accuracy - max_std_accuracy) > (\n",
    "            best_mean_accuracy - best_std_accuracy\n",
    "        ):\n",
    "            hyperparameters[\"epochs\"] = max_index + 1\n",
    "            best_hyperparameters = hyperparameters\n",
    "            best_mean_accuracy = max_mean_accuracy\n",
    "            best_std_accuracy = max_std_accuracy\n",
    "\n",
    "    # Model assessment.\n",
    "    logger.info(f\"Best hyperparameters: {best_hyperparameters}\")\n",
    "    logger.info(f\"Best mean accuracy: {best_mean_accuracy}\")\n",
    "    logger.info(f\"Best std accuracy: {best_std_accuracy}\") \n",
    "\n",
    "    # Average over 3 runs to offset random initialization.\n",
    "    test_results = defaultdict(list)\n",
    "    dev_results = defaultdict(list)\n",
    "    for test_id in range(3):\n",
    "        log_folder = os.path.join(\n",
    "            experiment_folder, f\"{outer_id:03d}\", f\"test_{test_id}\"\n",
    "        )\n",
    "        os.makedirs(log_folder, exist_ok=False)\n",
    "\n",
    "        model, data, trainer = training.init_geometric_traning(\n",
    "            log_folder,\n",
    "            device,\n",
    "            best_hyperparameters,\n",
    "            targets,\n",
    "            model_params=model_params,\n",
    "            dataset_params=dataset_params,\n",
    "            training_params=training_params,\n",
    "        )\n",
    "        # Run training.\n",
    "        train_dataset = \"dev\"\n",
    "        eval_dataset = \"test\"\n",
    "        trainer.train(\n",
    "            model=model,\n",
    "            named_trainloader=(\n",
    "                train_dataset,\n",
    "                data.geometric_loader(\n",
    "                    dataset=train_dataset, indices=cv.dev_indices\n",
    "                ),\n",
    "            ),\n",
    "            named_evalloader=(\n",
    "                eval_dataset,\n",
    "                data.geometric_loader(\n",
    "                    dataset=eval_dataset, indices=cv.test_indices\n",
    "                ),\n",
    "            ),\n",
    "            fold=f\"test_{test_id}\",\n",
    "        )\n",
    "        # Results.\n",
    "        train_results, eval_results = trainer.get_results(\n",
    "            train_dataset=train_dataset, eval_dataset=eval_dataset\n",
    "        )\n",
    "        dev_results[\"accuracy\"].append(\n",
    "            (train_results[\"accuracy\"][0][-1], train_results[\"accuracy\"][1][-1])\n",
    "        )\n",
    "        dev_results[\"recall\"].append(\n",
    "            (train_results[\"recall\"][0][-1], train_results[\"recall\"][1][-1])\n",
    "        )\n",
    "        dev_results[\"precision\"].append(\n",
    "            (\n",
    "                train_results[\"precision\"][0][-1],\n",
    "                train_results[\"precision\"][1][-1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        test_results[\"accuracy\"].append(\n",
    "            (eval_results[\"accuracy\"][0][-1], eval_results[\"accuracy\"][1][-1])\n",
    "        )\n",
    "        test_results[\"recall\"].append(\n",
    "            (eval_results[\"recall\"][0][-1], eval_results[\"recall\"][1][-1])\n",
    "        )\n",
    "        test_results[\"precision\"].append(\n",
    "            (eval_results[\"precision\"][0][-1], eval_results[\"precision\"][1][-1])\n",
    "        )\n",
    "\n",
    "    logger.info(f\"Dev: {dev_results}\")\n",
    "    logger.info(f\"Test: {test_results}\")\n",
    "    general_utils.close_logger(\"cv\")\n",
    "    break\n",
    "\n",
    "general_utils.close_all_loggers()\n",
    "print(\"Finished training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_utils.close_all_loggers"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c40931cbb4a31228df7bc840fc8745c5509fc7c9b0d60dae36a005e5fe0dba9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
