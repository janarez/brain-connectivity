{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "9c40931cbb4a31228df7bc840fc8745c5509fc7c9b0d60dae36a005e5fe0dba9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GIN < FC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pickle\r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from importlib import reload\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "from torch.utils.data import TensorDataset\r\n",
    "from torch_geometric.data import Data, DataLoader\r\n",
    "\r\n",
    "from torchinfo import summary\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append(\"..\")\r\n",
    "from brain_connectivity import model as bc\r\n",
    "from brain_connectivity.dense import ConnectivityDenseNet, ConnectivityMode\r\n",
    "from brain_connectivity.gin import GIN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DATA_FOLDER = '../data'\r\n",
    "PICKLE_FOLDER = '../pickles'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_metadata = pd.read_csv(f'{DATA_FOLDER}/patients-cleaned.csv', index_col=0)\r\n",
    "df_metadata.head(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select connectivity dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "THRESHOLD = 0.05                                          # 0.01, 0.05, 0.1, 0.15\r\n",
    "N = 20                                                   # 3, 5, 7, 10, 15, 20, 40\r\n",
    "CORR_TYPE = 'pearson'                                    # 'pearson', 'spearman', 'partial-pearson'\r\n",
    "THRESHOLD_METHOD = 'abs-group-avg-diff'                  # 'abs-sample-diff', 'abs-group-avg-diff'\r\n",
    "THRESHOLD_TYPE = 'min'                                   # 'min', 'max' or for kNN 'small', 'large'\r\n",
    "KNN = False                                              # Whether all or only top N neigbors are taken"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fc_folder = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}{\"-knn\" if KNN else \"\"}-{THRESHOLD_METHOD}'\r\n",
    "\r\n",
    "# Try Gini or SGD.\r\n",
    "# fc_folder = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}-gini'\r\n",
    "# fc_folder = f'{PICKLE_FOLDER}/fc-{CORR_TYPE}-sgd'\r\n",
    "\r\n",
    "fc_file_binary = f'{fc_folder}/{THRESHOLD_TYPE}-{f\"knn-{N}\" if KNN else f\"th-{THRESHOLD}\"}-binary.pickle'\r\n",
    "fc_file_real = f'{fc_folder}/{THRESHOLD_TYPE}-{f\"knn-{N}\" if KNN else f\"th-{THRESHOLD}\"}-real.pickle'\r\n",
    "\r\n",
    "# fc_file_binary = f'{fc_folder}/binary.pickle'\r\n",
    "# fc_file_real = f'{fc_folder}/real.pickle'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(f'{PICKLE_FOLDER}/fc-pearson.pickle', 'rb') as f:\r\n",
    "    raw_matrix = pickle.load(f)\r\n",
    "\r\n",
    "with open(fc_file_binary, 'rb') as f:\r\n",
    "    edge_index_matrix = pickle.load(f)\r\n",
    "\r\n",
    "with open(fc_file_real, 'rb') as f:\r\n",
    "    fc_matrix = pickle.load(f)\r\n",
    "\r\n",
    "\r\n",
    "num_samples, num_parcels, _ = edge_index_matrix.shape\r\n",
    "edge_index_matrix.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(f'{PICKLE_FOLDER}/test-indices.pickle', 'rb') as f:\r\n",
    "    test_indices = pickle.load(f)\r\n",
    "    \r\n",
    "train_indices = list(set(range(num_samples)) - set(test_indices))\r\n",
    "train_targets = df_metadata.iloc[train_indices][\"target\"].reset_index(drop=True)\r\n",
    "\r\n",
    "print(f'Train set size: {len(train_indices)}')\r\n",
    "print(f'Test set size: {len(test_indices)}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "device"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `Data` object fields\r\n",
    "\r\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\r\n",
    "\r\n",
    "- `data.edge_index`: Graph connectivity in COO format with shape `[2, num_edges]` and type `torch.long`\r\n",
    "\r\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\r\n",
    "\r\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\r\n",
    "\r\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select node features\r\n",
    "\r\n",
    "- onehot\r\n",
    "- correlations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Each nodes contains its row from FC matrix.\r\n",
    "def correlations_in_nodes(i):\r\n",
    "    return torch.from_numpy(fc_matrix[i]).to(torch.float32)\r\n",
    "\r\n",
    "\r\n",
    "# Each brain region is onehot encoded. See GIN for phenotype paper.\r\n",
    "def onehot_in_nodes(i):\r\n",
    "    return torch.diag(torch.ones(num_parcels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features_in_nodes = correlations_in_nodes\r\n",
    "num_node_features = num_parcels\r\n",
    "num_node_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graph_dataset = [Data(\r\n",
    "    x=features_in_nodes(i),  \r\n",
    "    edge_index=torch.from_numpy(np.asarray(np.nonzero(edge_index_matrix[i]))).to(torch.int64),\r\n",
    "    # y=torch.tensor([[1, 0]]  if target == 0 else [[0, 1]], dtype=torch.int64)\r\n",
    "    y=torch.tensor([target], dtype=torch.int64)\r\n",
    ").to(device) for target, i in zip(train_targets, train_indices)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'True train data: {len(graph_dataset)}')\r\n",
    "\r\n",
    "print('Data object')\r\n",
    "print(f'Edge index: {graph_dataset[0].edge_index.shape}')\r\n",
    "print(f'Node features: {graph_dataset[0].x.shape}')\r\n",
    "print(f'Target: {graph_dataset[0].y.shape}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dense dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dense_dataset = TensorDataset(\r\n",
    "    torch.from_numpy(raw_matrix[train_indices]), \r\n",
    "    torch.from_numpy(train_targets.values)\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define GIN & FC architectures"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Architecture FC.\r\n",
    "summary(ConnectivityDenseNet(\r\n",
    "    num_parcels, \r\n",
    "    ConnectivityMode.SINGLE, \r\n",
    "    num_node_features,\r\n",
    "    32,\r\n",
    "    num_sublayers=3\r\n",
    "))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Architecture GIN.\r\n",
    "summary(GIN(\r\n",
    "    size_in=num_node_features,\r\n",
    "    num_hidden_features=32,\r\n",
    "    num_sublayers=3\r\n",
    "))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NUM_FOLDS = 2\r\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, random_state=42, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training parameters settings.\r\n",
    "training_params = {\r\n",
    "    # Training regime.\r\n",
    "    'epochs': 100,\r\n",
    "    'validation_frequency': 1,\r\n",
    "\r\n",
    "    # Optimizer.\r\n",
    "    'optimizer': torch.optim.Adam,\r\n",
    "    'momentum': 0.9,\r\n",
    "    'learning_rate': 0.001,\r\n",
    "    'weight_decay': 0.0001,\r\n",
    "\r\n",
    "    # Scheduler.\r\n",
    "    'step_size': 50,\r\n",
    "    'gamma': 0.5,\r\n",
    "\r\n",
    "    # Loss.\r\n",
    "    'criterion': torch.nn.CrossEntropyLoss()\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model parameters settings.\r\n",
    "model_params = {\r\n",
    "    'size_in': num_node_features,\r\n",
    "    'num_hidden_features': 64,\r\n",
    "    'num_sublayers': 5\r\n",
    "}\r\n",
    "\r\n",
    "gin_params = {\r\n",
    "    'eps': 0.2\r\n",
    "}\r\n",
    "\r\n",
    "dense_params = {\r\n",
    "    'mode': ConnectivityMode.SINGLE,\r\n",
    "    'num_nodes': num_parcels\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Experiment folder.\r\n",
    "EXP_FOLDER = 'runs/fc-vs-gin'\r\n",
    "\r\n",
    "# Experiment.\r\n",
    "EXP_ID = 1\r\n",
    "\r\n",
    "BATCH_SIZE = 2\r\n",
    "\r\n",
    "MODEL_TYPE = bc.ModelType.GRAPH"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reload(bc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for fold_id, (train_index, val_index) in enumerate(skf.split(np.zeros(len(train_targets)), train_targets)):\r\n",
    "\r\n",
    "    # Init TB writer.\r\n",
    "    experiment_str = f'id={EXP_ID:03d},fold={fold_id}'\r\n",
    "    writer = SummaryWriter(f\"../{EXP_FOLDER}/{MODEL_TYPE}/{experiment_str}\")\r\n",
    "\r\n",
    "    # Init model.\r\n",
    "    if MODEL_TYPE == bc.ModelType.GRAPH:\r\n",
    "        net = GIN(**model_params, **gin_params).to(device)\r\n",
    "    elif MODEL_TYPE == bc.ModelType.DENSE:\r\n",
    "        net = ConnectivityDenseNet(**model_params, **dense_params).to(device)\r\n",
    "    else:\r\n",
    "        raise Exception('Unsupported model type.')\r\n",
    "\r\n",
    "    # Prepare data.\r\n",
    "    dataset = graph_dataset if MODEL_TYPE == bc.ModelType.GRAPH else dense_dataset\r\n",
    "    X_train = [graph_dataset[i] for i in train_index]\r\n",
    "    X_val = [dense_dataset[i] for i in val_index]\r\n",
    "\r\n",
    "    # NOTE: There is no problem in using `Geometric` `DataLoader` as standard one.\r\n",
    "    trainloader = DataLoader(X_train, batch_size=BATCH_SIZE, shuffle=True)\r\n",
    "    valloader = DataLoader(X_val, batch_size=BATCH_SIZE, shuffle=False)\r\n",
    "\r\n",
    "    # Save architecture.\r\n",
    "    with open(f\"../{EXP_FOLDER}/{MODEL_TYPE}/{experiment_str}/architecture\", 'w', encoding=\"utf-8\") as f:\r\n",
    "        if MODEL_TYPE == bc.ModelType.GRAPH:\r\n",
    "            f.write(fc_folder + '\\n' + fc_file_binary + '\\n' + fc_file_real + '\\n')\r\n",
    "        f.write(features_in_nodes.__str__() + '\\n')\r\n",
    "        f.write(training_params.__str__() + '\\n')\r\n",
    "        f.write(net.__str__() + '\\n\\n')\r\n",
    "        f.write(str(summary(net)))\r\n",
    "\r\n",
    "    # Init model wrapper.\r\n",
    "    model = bc.Model(\r\n",
    "        model=net, \r\n",
    "        trainloader=trainloader, \r\n",
    "        valloader=valloader,\r\n",
    "        writer=writer,\r\n",
    "        **training_params\r\n",
    "    )\r\n",
    "    \r\n",
    "    # Run training.\r\n",
    "    model.train()\r\n",
    "\r\n",
    "\r\n",
    "    # Single fold during exploration.\r\n",
    "    #break\r\n",
    "\r\n",
    "print('Finished training')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}